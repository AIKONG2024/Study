from keras.preprocessing.text import Tokenizer
import numpy as np

text = "나는 진짜 진짜 매우 매우 맛있는 밥을 엄청 마구 마구 마구 먹었다."
text2 = "상헌이가 선생님을 괴롭힌다. 상헌이는 못생겼다. 상헌이는 마구 마구 못생겼다."

### 아래 수정.

token = Tokenizer()
token.fit_on_texts([text, text2]) 
print(token.word_index)
#{'마구': 1, '진짜': 2, '매우': 3, '상헌이는': 4, '못생겼다': 5, '나는': 6, '맛있는': 7, '밥을': 8, 
# '엄청': 9, '먹었다': 10, '상헌이가': 11, '선생님을': 12, '괴롭힌다': 13}

print(token.word_counts)
#OrderedDict([('나는', 1), ('진짜', 2), ('매우', 2), ('맛있는', 1), ('밥을', 1), ('엄청', 1), ('마구', 5), ('먹었다', 1), 
# ('상헌이가', 1), ('선생님을', 1), ('괴롭힌다', 1), ('상헌이는', 2), ('못생겼다', 2)])

x = np.array(token.texts_to_sequences([text + text2]))
print(x)
# [list([6, 2, 2, 3, 3, 7, 8, 9, 1, 1, 1, 10]) #0 4 5
#  list([11, 12, 13, 4, 5, 4, 1, 1, 5])] #0 2 3 6 7 8 9 10
print(x.shape)#(2,)
# seq_x1 = np.array(x[0]) #(12,)
# seq_x2 = np.array(x[1]) #(9,)

# print(seq_x1.shape)
# print(seq_x2.shape)

#to_categorical
from keras.utils import to_categorical
x1 = to_categorical(x)
print(x1.shape)
x1 = x1[:,:,1:]
print(x1)
'''
[[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]]
'''

# 2. scikit-learn의 onehot
# from sklearn.preprocessing import OneHotEncoder 
# ohe = OneHotEncoder(sparse=False)
# x3 = ohe.fit_transform(x.reshape(-1,1))
# print(x3)
'''
[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]
'''

# 3. pandas get_dummies()
# import pandas as pd
# x5 = pd.get_dummies(x.reshape(-1,)).astype(int)
# print(x5)
'''
    1   2   3   4   5   6   7   8   9   10  11  12  13
0    0   0   0   0   0   1   0   0   0   0   0   0   0
1    0   1   0   0   0   0   0   0   0   0   0   0   0
2    0   1   0   0   0   0   0   0   0   0   0   0   0
3    0   0   1   0   0   0   0   0   0   0   0   0   0
4    0   0   1   0   0   0   0   0   0   0   0   0   0
5    0   0   0   0   0   0   1   0   0   0   0   0   0
6    0   0   0   0   0   0   0   1   0   0   0   0   0
7    0   0   0   0   0   0   0   0   1   0   0   0   0
8    1   0   0   0   0   0   0   0   0   0   0   0   0
9    1   0   0   0   0   0   0   0   0   0   0   0   0
10   1   0   0   0   0   0   0   0   0   0   0   0   0
11   0   0   0   0   0   0   0   0   0   1   0   0   0
12   0   0   0   0   0   0   0   0   0   0   1   0   0
13   0   0   0   0   0   0   0   0   0   0   0   1   0
14   0   0   0   0   0   0   0   0   0   0   0   0   1
15   0   0   0   1   0   0   0   0   0   0   0   0   0
16   0   0   0   0   1   0   0   0   0   0   0   0   0
17   0   0   0   1   0   0   0   0   0   0   0   0   0
18   1   0   0   0   0   0   0   0   0   0   0   0   0
19   1   0   0   0   0   0   0   0   0   0   0   0   0
20   0   0   0   0   1   0   0   0   0   0   0   0   0
'''
